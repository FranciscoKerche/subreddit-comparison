{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals of Social Data Science\n",
    "# Week 4 Day 1 Lab. Classification \n",
    "\n",
    "In this lab, you will be encouraged to explore your subreddits of choice using multinomial naive bayes and k-means classifications. Determine which one is more suitable using accuracy scores. Use both the TfIDFVectorizer and the CountVectorizer. \n",
    "\n",
    "Consider the use of stop words and lemmatisation. \n",
    "\n",
    "1. Plot the documents using t-SNE and then color the documents according the most accurate solution. \n",
    "2. For Naive Bayes report the 5 most informative terms per solution.  \n",
    "* Would you be able to report the 5 most informative terms with k-means? This would be a bit far out for this lecture but if you are adventurous you can explore approaches like k-nearest neighbors using the centroids (as in report the 5 nearest neighbors to the centroid for each of the k solutions). \n",
    "\n",
    "There is only limited example code for this exercise. It is up to you to stitch together what you have learned as well as potentially draw upon external sources. On Wednesday we will provide an example solution.\n",
    "\n",
    "Some guidance: \n",
    "1. Transform your headlines into a list similar to the walkthrough: [(\"headline (and maybe selftext)\", \"subreddit_label\"), (\"next headline\", \"next subreddit_label\")]\n",
    " * Create one long list for all three subreddits to send to the Vectorizer. This is different to what I showed in Week 3 Day 3 where we had a separate vectorizer for each subreddit. To help you out I've started some code that creates a DataFrame for all the subs. \n",
    "2. Consider your tokenization. Will you use stop words or not? \n",
    "3. Consider plotting the classification on t-SNE to get some intuitions for how the solution maps out visually. \n",
    "4. Remember, are you classifying the documents using the terms? Or classifying the terms using the documents? Be careful with how you set this up. Notice that in the examples in the walkthrough we were classifying the documents using the terms. \n",
    "5. Consider the structure of this repository. Will you want to place some code for a plotting function in the `analysis.py`? What about creating a function under `text_processor.py` to transform the reddit data into the data structure needed. You can do everything in this Jupyter lab notebook but you should use this opportunity to think about how you might make use of this structure in order to help keep your code tidy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from models.reddit_scraper import RedditScraper\n",
    "from config.settings import USER_AGENT\n",
    "from utils.analysis import *\n",
    "\n",
    "scraper = RedditScraper(USER_AGENT)\n",
    "subs_of_interest = ['AmItheAsshole', 'confessions', 'tifu']\n",
    "\n",
    "posts_list = []\n",
    "\n",
    "for sub in subs_of_interest:    \n",
    "    posts = scraper.get_subreddit_posts(sub, limit=100, cache=True)\n",
    "    df = create_posts_dataframe(posts)\n",
    "    df['subreddit'] = sub\n",
    "    posts_list.append(df)\n",
    "\n",
    "posts_df = pd.concat(posts_list)\n",
    "posts_df = posts_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>time</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for being mad my friend didn’t pay me back?</td>\n",
       "      <td>So I’ve paid for two things in the past year a...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>self.AmItheAsshole</td>\n",
       "      <td>2024-11-04 17:55:17</td>\n",
       "      <td>VirgoEsti</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AITA for not responding to the father of my un...</td>\n",
       "      <td>So to give context I dated this guy for a coup...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>self.AmItheAsshole</td>\n",
       "      <td>2024-11-04 17:51:35</td>\n",
       "      <td>True_Traffic_9928</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA - Child Care and Individual Careers.</td>\n",
       "      <td>I was wondering if I’ve been the asshole to my...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>self.AmItheAsshole</td>\n",
       "      <td>2024-11-04 17:48:37</td>\n",
       "      <td>movie2019</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIBTA if I told my friend she can’t be friends...</td>\n",
       "      <td>I (20F) have been friends with Beth (20F) for ...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>self.AmItheAsshole</td>\n",
       "      <td>2024-11-04 17:42:50</td>\n",
       "      <td>SierraWe</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA for screaming at my mom to die in a car c...</td>\n",
       "      <td>My mom was close with both me (34f) and my sis...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>self.AmItheAsshole</td>\n",
       "      <td>2024-11-04 17:42:12</td>\n",
       "      <td>Katthevamp</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>TIFU by telling my friend congrats on her daug...</td>\n",
       "      <td>Obligatory \"Didn't happen today.\"\\n\\nWhen I wa...</td>\n",
       "      <td>https://www.reddit.com/r/tifu/comments/1gdrfgv...</td>\n",
       "      <td>self.tifu</td>\n",
       "      <td>2024-10-28 02:06:24</td>\n",
       "      <td>10Kfireants</td>\n",
       "      <td>tifu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>TIFU by thinking something was actually wrong ...</td>\n",
       "      <td>So kind of embarrassing but I felt it was nece...</td>\n",
       "      <td>https://www.reddit.com/r/tifu/comments/1gdp9fh...</td>\n",
       "      <td>self.tifu</td>\n",
       "      <td>2024-10-28 00:14:14</td>\n",
       "      <td>Gumbinator10</td>\n",
       "      <td>tifu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>TIFU by trying to make my boyfriend choose bet...</td>\n",
       "      <td>Hey, do last time I told everybody about how I...</td>\n",
       "      <td>https://www.reddit.com/r/tifu/comments/1gdommr...</td>\n",
       "      <td>self.tifu</td>\n",
       "      <td>2024-10-27 23:43:41</td>\n",
       "      <td>ThisAntiMatter</td>\n",
       "      <td>tifu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>TIFU passing gas on the dance floor</td>\n",
       "      <td>I’m a mid 30s Female. last night I went out fo...</td>\n",
       "      <td>https://www.reddit.com/r/tifu/comments/1gdmvza...</td>\n",
       "      <td>self.tifu</td>\n",
       "      <td>2024-10-27 22:20:36</td>\n",
       "      <td>queerharveybabe</td>\n",
       "      <td>tifu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>TIFU by ordering sex toys on Amazon</td>\n",
       "      <td>Sooooo today I fucked up, I decided to order s...</td>\n",
       "      <td>https://www.reddit.com/r/tifu/comments/1gdjaij...</td>\n",
       "      <td>self.tifu</td>\n",
       "      <td>2024-10-27 19:37:53</td>\n",
       "      <td>Wecandodabs</td>\n",
       "      <td>tifu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0     AITA for being mad my friend didn’t pay me back?   \n",
       "1    AITA for not responding to the father of my un...   \n",
       "2            AITA - Child Care and Individual Careers.   \n",
       "3    WIBTA if I told my friend she can’t be friends...   \n",
       "4    AITA for screaming at my mom to die in a car c...   \n",
       "..                                                 ...   \n",
       "295  TIFU by telling my friend congrats on her daug...   \n",
       "296  TIFU by thinking something was actually wrong ...   \n",
       "297  TIFU by trying to make my boyfriend choose bet...   \n",
       "298               TIFU passing gas on the dance floor    \n",
       "299                TIFU by ordering sex toys on Amazon   \n",
       "\n",
       "                                              selftext  \\\n",
       "0    So I’ve paid for two things in the past year a...   \n",
       "1    So to give context I dated this guy for a coup...   \n",
       "2    I was wondering if I’ve been the asshole to my...   \n",
       "3    I (20F) have been friends with Beth (20F) for ...   \n",
       "4    My mom was close with both me (34f) and my sis...   \n",
       "..                                                 ...   \n",
       "295  Obligatory \"Didn't happen today.\"\\n\\nWhen I wa...   \n",
       "296  So kind of embarrassing but I felt it was nece...   \n",
       "297  Hey, do last time I told everybody about how I...   \n",
       "298  I’m a mid 30s Female. last night I went out fo...   \n",
       "299  Sooooo today I fucked up, I decided to order s...   \n",
       "\n",
       "                                                   url              domain  \\\n",
       "0    https://www.reddit.com/r/AmItheAsshole/comment...  self.AmItheAsshole   \n",
       "1    https://www.reddit.com/r/AmItheAsshole/comment...  self.AmItheAsshole   \n",
       "2    https://www.reddit.com/r/AmItheAsshole/comment...  self.AmItheAsshole   \n",
       "3    https://www.reddit.com/r/AmItheAsshole/comment...  self.AmItheAsshole   \n",
       "4    https://www.reddit.com/r/AmItheAsshole/comment...  self.AmItheAsshole   \n",
       "..                                                 ...                 ...   \n",
       "295  https://www.reddit.com/r/tifu/comments/1gdrfgv...           self.tifu   \n",
       "296  https://www.reddit.com/r/tifu/comments/1gdp9fh...           self.tifu   \n",
       "297  https://www.reddit.com/r/tifu/comments/1gdommr...           self.tifu   \n",
       "298  https://www.reddit.com/r/tifu/comments/1gdmvza...           self.tifu   \n",
       "299  https://www.reddit.com/r/tifu/comments/1gdjaij...           self.tifu   \n",
       "\n",
       "                   time             author      subreddit  \n",
       "0   2024-11-04 17:55:17          VirgoEsti  AmItheAsshole  \n",
       "1   2024-11-04 17:51:35  True_Traffic_9928  AmItheAsshole  \n",
       "2   2024-11-04 17:48:37          movie2019  AmItheAsshole  \n",
       "3   2024-11-04 17:42:50           SierraWe  AmItheAsshole  \n",
       "4   2024-11-04 17:42:12         Katthevamp  AmItheAsshole  \n",
       "..                  ...                ...            ...  \n",
       "295 2024-10-28 02:06:24        10Kfireants           tifu  \n",
       "296 2024-10-28 00:14:14       Gumbinator10           tifu  \n",
       "297 2024-10-27 23:43:41     ThisAntiMatter           tifu  \n",
       "298 2024-10-27 22:20:36    queerharveybabe           tifu  \n",
       "299 2024-10-27 19:37:53        Wecandodabs           tifu  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "posts_dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise NBC results: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise k-Means results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
